{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVcO6p3mw3y4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier  # might use this later\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"/content/LIHC_DESeq_significant_vst_WITH_META.csv\")\n",
        "print(\"shape of\", df.shape)\n",
        "\n",
        "print(df[\"Stage_main\"].value_counts())\n",
        "\n",
        "metadata_cols = [\n",
        "    \"Sample_ID_full\", \"Sample_short\", \"Stage_raw\",\n",
        "    \"Stage_main\", \"Patient_ID\", \"Diagnosis_Age\"\n",
        "]\n",
        "\n",
        "gene_columns = []\n",
        "\n",
        "for col in df.columns:\n",
        "    if col not in metadata_cols:\n",
        "        gene_columns.append(col)\n",
        "\n",
        "genes_df = df[gene_columns]\n",
        "\n",
        "X = genes_df.values\n",
        "y = df[\"Stage_main\"].values\n",
        "\n",
        "print(\"\\nTotal DESeq2-significant gene features:\", genes_df.shape[1])\n",
        "print(\"Stage distribution before filtering:\")\n",
        "print(pd.Series(y).value_counts())\n",
        "\n",
        "\n",
        "valid_stages = ['Stage I', 'Stage II', 'Stage III']\n",
        "sample_mask = np.isin(y, valid_stages)\n",
        "X = X[sample_mask]\n",
        "y = y[sample_mask]\n",
        "\n",
        "print(\"after filtering:\", X.shape[0])\n",
        "print(\"remaining counts:\", np.unique(y, return_counts=True))\n",
        "\n",
        "df[\"Stage_for_ML\"] = df[\"Stage_main\"].replace({\"Other\": \"Stage III\"})\n",
        "print(\"\\nStage counts after adjusting labels:\")\n",
        "print(df[\"Stage_for_ML\"].value_counts())\n",
        "\n",
        "df = df[df[\"Stage_for_ML\"].isin(valid_stages)]\n",
        "print(\"\\nFinal stage counts used for training:\")\n",
        "print(df[\"Stage_for_ML\"].value_counts())\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    stratify=y,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"BEFORE SMOTE:\")\n",
        "print(pd.Series(y_train).value_counts())\n",
        "print(\"distribution:\")\n",
        "print(pd.Series(y_test).value_counts())\n",
        "\n",
        "\n",
        "\n",
        "orig_counts = Counter(y_train)\n",
        "print(\"\\nOriginal class breakdown:\", ori_counts)\n",
        "\n",
        "max = max(orig_counts.values())\n",
        "smote_strategy = {}\n",
        "\n",
        "for label, count in orig_counts.items():\n",
        "    if label in [\"Stage II\", \"Stage III\"]:\n",
        "        smote_strategy[label] = max\n",
        "    else:\n",
        "        smote_strategy[label] = count\n",
        "\n",
        "print(\"SMOTE:\", smote_strategy)\n",
        "\n",
        "sm = SMOTE(sampling_strategy=smote_strategy, random_state=42, k_neighbors=3)\n",
        "X_train_bal, y_train_bal = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"AFTER SMOTE:\")\n",
        "print(pd.Series(y_train_bal).value_counts())\n",
        "\n",
        "\n",
        "smote = SMOTE(\n",
        "    sampling_strategy=smote_strategy,\n",
        "    random_state=42,\n",
        "    k_neighbors=3\n",
        ")\n",
        "\n",
        "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"\\nAfter SMOTE resampling:\")\n",
        "print(pd.Series(y_train_balanced).value_counts())\n",
        "\n",
        "\n",
        "display(df.head())\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "\n",
        "# Using some classic ML models â€” nothing fancy, just testing things out\n",
        "ml_models = {\n",
        "    \"LogisticRegression\": LogisticRegression(max_iter=5000, multi_class=\"multinomial\"),\n",
        "    \"LinearSVM\": LinearSVC(),\n",
        "    \"RBF_SVM\": SVC(kernel=\"rbf\", probability=False),\n",
        "    \"RandomForest\": RandomForestClassifier(n_estimators=300, random_state=42),\n",
        "    \"GradientBoosting\": GradientBoostingClassifier()\n",
        "}\n",
        "\n",
        "\n",
        "for label, model in ml_models.items():\n",
        "    print(f\"Training model: {label}\")\n",
        "    model.fit(X_train_balanced, y_train_balanced)\n",
        "    y_predicted = model.predict(X_test)\n",
        "\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_test, y_predicted))\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_predicted))\n",
        "\n",
        "\n",
        "\n",
        "from imblearn.over_sampling import BorderlineSMOTE\n",
        "\n",
        "print(\"Borderline-SMOTE\")\n",
        "\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(X_vals, y_labels, test_size=0.2, stratify=y_labels, random_state=42)\n",
        "bsm = BorderlineSMOTE(random_state=42)\n",
        "X_tr_resampled, y_tr_resampled = bsm.fit_resample(X_tr, y_tr)\n",
        "\n",
        "\n",
        "for name, model in ml_models.items():\n",
        "    model.fit(X_tr_resampled, y_tr_resampled)\n",
        "    preds = model.predict(X_te)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_te, preds))\n",
        "    print(\"Report:\")\n",
        "    print(classification_report(y_te, preds))\n",
        "\n",
        "from imblearn.over_sampling import ADASYN\n",
        "\n",
        "adasyn = ADASYN(random_state=42)\n",
        "X_tr_res, y_tr_res = adasyn.fit_resample(X_tr, y_tr)\n",
        "\n",
        "print(\"ADASYN Sampling\")\n",
        "for name, model in ml_models.items():\n",
        "    model.fit(X_tr_res, y_tr_res)\n",
        "    y_pred = model.predict(X_te)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_te, y_pred))\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_te, y_pred))\n",
        "\n",
        "\n",
        "from imblearn.combine import SMOTEENN\n",
        "\n",
        "smote_enn = SMOTEENN(random_state=42)\n",
        "X_res, y_res = smote_enn.fit_resample(X_tr, y_tr)\n",
        "\n",
        "print(\"SMOTEENN Combination\")\n",
        "for model_name, model in ml_models.items():\n",
        "    model.fit(X_res, y_res)\n",
        "    y_pred = model.predict(X_te)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_te, y_pred))\n",
        "    print(\"Report:\")\n",
        "    print(classification_report(y_te, y_pred))\n",
        "from lime.lime_tabular import LimeTabularExplainer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "non_gene_cols = [\n",
        "    \"Sample_ID_full\", \"Sample_short\", \"Stage_raw\",\n",
        "    \"Stage_main\", \"Patient_ID\", \"Diagnosis_Age\"\n",
        "]\n",
        "\n",
        "X_lime = df.drop(columns=non_gene_cols)\n",
        "y_lime = df[\"Stage_main\"]\n",
        "\n",
        "keep_mask = y_lime.isin([\"Stage I\", \"Stage II\", \"Stage III\"])\n",
        "X_lime = X_lime.loc[keep_mask]\n",
        "y_lime = y_lime.loc[keep_mask]\n",
        "\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(X_lime, y_lime, test_size=0.2, stratify=y_lime, random_state=42)\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "y_tr_enc = encoder.fit_transform(y_tr)\n",
        "y_te_enc = encoder.transform(y_te)\n",
        "\n",
        "smote = BorderlineSMOTE(random_state=42, k_neighbors=3)\n",
        "X_bal, y_bal = smote.fit_resample(X_tr.values, y_tr_enc)\n",
        "\n",
        "clf = LogisticRegression(max_iter=5000, multi_class=\"multinomial\")\n",
        "clf.fit(X_bal, y_bal)\n",
        "\n",
        "lime = LimeTabularExplainer(\n",
        "    training_data=X_bal,\n",
        "    feature_names=X_lime.columns.tolist(),\n",
        "    class_names=encoder.classes_.tolist(),\n",
        "    mode=\"classification\",\n",
        "    discretize_continuous=True\n",
        ")\n",
        "\n",
        "i=0\n",
        "explanation = lime.explain_instance(X_te.values[i], clf.predict_proba, num_features=200)\n",
        "explanation.show_in_notebook(show_table=True)\n",
        "import gseapy as gp\n",
        "\n",
        "if clf.coef_.shape[0] == 1:\n",
        "    importance_scores = np.abs(clf.coef_[0])\n",
        "else:\n",
        "    importance_scores = np.max(np.abs(clf.coef_), axis=0)\n",
        "\n",
        "gene_names = X_lime.columns\n",
        "importance_df = pd.DataFrame({\n",
        "    'gene': gene_names,\n",
        "    'importance': importance_scores\n",
        "}).sort_values(by='importance', ascending=False)\n",
        "\n",
        "top_genes = importance_df.head(500)['gene'].tolist()\n",
        "print(\"top genes\", top_genes[:5])\n",
        "\n",
        "enr = gp.enrichr(\n",
        "    gene_list=top_genes,\n",
        "    gene_sets=['KEGG_2021_Human', 'GO_Biological_Process_2021'],\n",
        "    organism='Human',\n",
        ")\n",
        "\n",
        "\n",
        "enriched = enr.results\n",
        "significant = enriched[enriched['Adjusted P-value'] < 0.05].head(10)\n",
        "\n",
        "if not significant.empty:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.barh(significant['Term'], -np.log10(significant['Adjusted P-value']), color='skyblue')\n",
        "    plt.xlabel('-log10(Adjusted P-value)')\n",
        "    plt.title('Top Enriched Pathways')\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}